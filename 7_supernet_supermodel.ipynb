{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8682565a",
   "metadata": {},
   "source": [
    "# Zadanie 7 — SuperNet i Supermodel\n",
    "\n",
    "Cel:\n",
    "1) Stworzyć **Supermodel** — hybrydowy model ODE z neuronową korektą:\n",
    "   ẏ(t) = f_ODE(y; θ_calib) + g_φ(y, t)\n",
    "2) Stworzyć **SuperNet** — rozszerzenie PINN na rodzinę parametrów terapii:\n",
    "   wejście: (x, y, t, p_dose), wyjście: [Ŝ, R̂, Î, Ĉ]\n",
    "3) Porównać predykcje obu modeli z PDE i ODE.\n",
    "4) Zapisać wykresy do figs/, metryki do out/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb33930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time, random, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, asdict\n",
    "import copy\n",
    "\n",
    "# Katalogi\n",
    "Path(\"figs\").mkdir(exist_ok=True)\n",
    "Path(\"out\").mkdir(exist_ok=True)\n",
    "\n",
    "def savefig_root(name, dpi=160):\n",
    "    \"\"\"Zapisuje wykres w katalogu głównym projektu\"\"\"\n",
    "    plt.savefig(name, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[Zapisano wykres] {name}\")\n",
    "\n",
    "def savefig_fig(name, dpi=160):\n",
    "    \"\"\"Zapisuje wykres w figs/\"\"\"\n",
    "    if not str(name).startswith(\"figs/\"):\n",
    "        name = f\"figs/{name}\"\n",
    "    plt.savefig(name, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[Zapisano wykres] {name}\")\n",
    "\n",
    "def save_json(obj, path):\n",
    "    \"\"\"Zapisuje JSON do out/\"\"\"\n",
    "    if not str(path).startswith(\"out/\"):\n",
    "        path = f\"out/{path}\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    print(f\"[Zapisano JSON] {path}\")\n",
    "\n",
    "def save_csv(df, path):\n",
    "    \"\"\"Zapisuje CSV do out/\"\"\"\n",
    "    if not str(path).startswith(\"out/\"):\n",
    "        path = f\"out/{path}\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"[Zapisano CSV] {path}\")\n",
    "\n",
    "# Metryki\n",
    "def rmse(pred, true):\n",
    "    return np.sqrt(np.mean((pred - true)**2))\n",
    "\n",
    "def mae(pred, true):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "# Reprodukowalność\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(123)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(123)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                     \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"[Device] Używam: {device}\")\n",
    "\n",
    "# tqdm dla progress bars\n",
    "try:\n",
    "    from tqdm import tqdm, trange\n",
    "    TQDM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TQDM_AVAILABLE = False\n",
    "    print(\"[INFO] tqdm niedostępny - progress bars wyłączone\")\n",
    "\n",
    "# SciPy dla integracji ODE\n",
    "try:\n",
    "    from scipy.integrate import solve_ivp\n",
    "    SCIPY_AVAILABLE = True\n",
    "    print(\"[OK] SciPy dostępny\")\n",
    "except Exception as e:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    print(\"Uwaga: SciPy niedostępny:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b9fa1",
   "metadata": {},
   "source": [
    "## 1. Importy modułów PDE i ODE\n",
    "\n",
    "Importujemy istniejące moduły z poprzednich zadań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b926e92",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "# --- Import modułu PDE (Zadanie 2) ---\n",
    "PDE_OK = True\n",
    "try:\n",
    "    candidates = [\"2_tumor_diffusion_pde_analysis.py\", \"tumor_diffusion_pde_analysis.py\"]\n",
    "    pdemod = None\n",
    "    for cand in candidates:\n",
    "        if Path(cand).exists():\n",
    "            spec = importlib.util.spec_from_file_location(\"pdemod\", cand)\n",
    "            pdemod = importlib.util.module_from_spec(spec)\n",
    "            sys.modules[\"pdemod\"] = pdemod\n",
    "            spec.loader.exec_module(pdemod)\n",
    "            break\n",
    "    if pdemod is None:\n",
    "        raise FileNotFoundError(\"Nie znaleziono pliku modułu PDE.\")\n",
    "\n",
    "    # Pobierz obiekty z modułu PDE\n",
    "    Grid = pdemod.Grid\n",
    "    Params = pdemod.Params\n",
    "    run_simulation = pdemod.run_simulation\n",
    "    init_fields = pdemod.init_fields\n",
    "    tumor_burden = pdemod.tumor_burden\n",
    "    p_pde_base = pdemod.p  # bazowe parametry PDE\n",
    "\n",
    "    print(\"[OK] Moduł PDE załadowany.\")\n",
    "except Exception as e:\n",
    "    PDE_OK = False\n",
    "    print(\"Uwaga: nie udało się załadować modułu PDE:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2b21f",
   "metadata": {},
   "source": [
    "## 2. Definicja parametrów ODE\n",
    "\n",
    "Używamy tych samych parametrów co w Zadaniu 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b135d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ODEParams:\n",
    "    # Wzrost logistyczny\n",
    "    rho_S: float = 0.04\n",
    "    rho_R: float = 0.03\n",
    "    K: float = 1.0\n",
    "\n",
    "    # Cytotoksyczność\n",
    "    alpha_S: float = 0.8\n",
    "    alpha_R: float = 0.12\n",
    "\n",
    "    # Immunologia\n",
    "    sigma: float = 0.05\n",
    "    delta: float = 0.1\n",
    "    gamma_S: float = 0.02\n",
    "    gamma_R: float = 0.02\n",
    "\n",
    "    # Farmakokinetyka leku\n",
    "    lam: float = 0.2\n",
    "    beta: float = 0.0\n",
    "\n",
    "    # Indukcja oporności\n",
    "    mu_max: float = 0.05\n",
    "    C50: float = 0.2\n",
    "    m_hill: int = 3\n",
    "\n",
    "    # Dawkowanie\n",
    "    dose_type: str = \"infusion_const\"  # dla tego zadania używamy infuzji\n",
    "    dose_A: float = 1.0\n",
    "    dose_period: float = 5.0\n",
    "    infusion_rate: float = 0.15\n",
    "\n",
    "def mu_of_C(C, mu_max, C50, m):\n",
    "    \"\"\"Funkcja Hill dla indukcji oporności\"\"\"\n",
    "    C_nonneg = np.maximum(C, 0.0)\n",
    "    ratio = np.power(C_nonneg / (C50 + 1e-12), m)\n",
    "    return mu_max * (ratio / (1.0 + ratio))\n",
    "\n",
    "def dosing_term_exact(t, dt, period, A):\n",
    "    \"\"\"Bolus jako krótki impuls\"\"\"\n",
    "    tau = 0.01 * period\n",
    "    phase = t % period\n",
    "    return A / tau if phase < tau else 0.0\n",
    "\n",
    "def ode_rhs(t, y, p: ODEParams, dt_for_dose=None):\n",
    "    \"\"\"\n",
    "    Prawa strona ODE: dy/dt = f(t, y; p)\n",
    "    y = [S, R, I, C]\n",
    "    \"\"\"\n",
    "    S, R, I, C = y\n",
    "    N = S + R\n",
    "\n",
    "    # Wzrost logistyczny\n",
    "    dS = p.rho_S * S * (1 - N/p.K)\n",
    "    dR = p.rho_R * R * (1 - N/p.K)\n",
    "\n",
    "    # Zabijanie lekiem i immunologią\n",
    "    dS -= p.alpha_S * C * S + p.gamma_S * I * S\n",
    "    dR -= p.alpha_R * C * R + p.gamma_R * I * R\n",
    "\n",
    "    # Indukcja oporności\n",
    "    mu = mu_of_C(C, p.mu_max, p.C50, p.m_hill)\n",
    "    dS -= mu * S\n",
    "    dR += mu * S\n",
    "\n",
    "    # Immunologia\n",
    "    dI = p.sigma * N - p.delta * I\n",
    "\n",
    "    # Lek\n",
    "    dC = -p.lam * C - p.beta * C * N\n",
    "    if p.dose_type == \"infusion_const\":\n",
    "        I_in = p.infusion_rate\n",
    "    elif p.dose_type == \"bolus_periodic\":\n",
    "        I_in = dosing_term_exact(t, dt_for_dose if dt_for_dose is not None else 1e-2,\n",
    "                                 p.dose_period, p.dose_A)\n",
    "    else:\n",
    "        I_in = 0.0\n",
    "    dC += I_in\n",
    "\n",
    "    return np.array([dS, dR, dI, dC])\n",
    "\n",
    "def simulate_ode(p: ODEParams, y0, t_grid):\n",
    "    \"\"\"\n",
    "    Symulacja ODE na siatce czasowej t_grid.\n",
    "    Zwraca słownik z polami: t, S, R, I, C, TB.\n",
    "    \"\"\"\n",
    "    if not SCIPY_AVAILABLE:\n",
    "        raise RuntimeError(\"SciPy wymagany do symulacji ODE\")\n",
    "\n",
    "    dt_effective = np.mean(np.diff(t_grid)) if len(t_grid) > 1 else 1e-2\n",
    "\n",
    "    def fun(t, y):\n",
    "        return ode_rhs(t, y, p, dt_for_dose=dt_effective)\n",
    "\n",
    "    sol = solve_ivp(fun, (t_grid[0], t_grid[-1]), y0, t_eval=t_grid,\n",
    "                   rtol=1e-7, atol=1e-9)\n",
    "    if not sol.success:\n",
    "        raise RuntimeError(sol.message)\n",
    "\n",
    "    Y = sol.y.T  # shape: [T, 4]\n",
    "    S, R, I, C = Y[:, 0], Y[:, 1], Y[:, 2], Y[:, 3]\n",
    "    TB = S + R\n",
    "\n",
    "    return {\"t\": t_grid, \"S\": S, \"R\": R, \"I\": I, \"C\": C, \"TB\": TB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737431c",
   "metadata": {},
   "source": [
    "## 3. Generowanie/wczytanie danych referencyjnych PDE\n",
    "\n",
    "TODO: Dostosuj do swoich istniejących danych lub użyj symulacji PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_generate_pde_reference(T=6.0, N=64, solver=\"semi_implicit\"):\n",
    "    \"\"\"\n",
    "    Wczytuje lub generuje trajektorię TB(t) z PDE.\n",
    "\n",
    "    TODO: Jeśli masz zapisane dane z wcześniejszych zadań (np. po asymilacji),\n",
    "    wczytaj je tutaj. W przeciwnym razie uruchom symulację PDE.\n",
    "\n",
    "    Zwraca: dict {\"t\": array, \"TB\": array, \"S_final\": array, \"R_final\": array, ...}\n",
    "    \"\"\"\n",
    "    # Próba wczytania z istniejącego pliku\n",
    "    possible_files = [\n",
    "        \"out/pinn_reference_pde.csv\",\n",
    "        \"out/assimilation_pde_trajectory.csv\",\n",
    "        \"out/compare_solvers_same_dt.csv\",\n",
    "    ]\n",
    "\n",
    "    for fname in possible_files:\n",
    "        if Path(fname).exists():\n",
    "            df = pd.read_csv(fname)\n",
    "            # Sprawdź format\n",
    "            if \"t\" in df.columns and \"tumor_burden\" in df.columns:\n",
    "                print(f\"[OK] Wczytano PDE z: {fname}\")\n",
    "                return {\"t\": df[\"t\"].values, \"TB\": df[\"tumor_burden\"].values}\n",
    "            elif \"t\" in df.columns and \"TB_explicit\" in df.columns:\n",
    "                print(f\"[OK] Wczytano PDE z: {fname}\")\n",
    "                return {\"t\": df[\"t\"].values, \"TB\": df[\"TB_explicit\"].values}\n",
    "\n",
    "    # Jeśli nie znaleziono, wygeneruj nową symulację\n",
    "    if PDE_OK:\n",
    "        print(\"[INFO] Generuję nową symulację PDE...\")\n",
    "        grid = Grid(Nx=N, Ny=N)\n",
    "        p = copy.deepcopy(p_pde_base)\n",
    "        p.dose_type = \"infusion_const\"\n",
    "        p.infusion_rate = 0.15\n",
    "\n",
    "        dt = 0.01\n",
    "\n",
    "        (S_final, R_final, I_final, C_final), traj, info = run_simulation(solver, grid, p, T=T, dt=dt, save_every=50)\n",
    "\n",
    "        t_arr = np.array([rec[\"t\"] for rec in traj])\n",
    "        TB_arr = np.array([rec[\"tumor_burden\"] for rec in traj])\n",
    "\n",
    "        # Zapisz do pliku\n",
    "        df_ref = pd.DataFrame({\"t\": t_arr, \"tumor_burden\": TB_arr})\n",
    "        save_csv(df_ref, \"supermodel_pde_reference.csv\")\n",
    "\n",
    "        return {\n",
    "            \"t\": t_arr,\n",
    "            \"TB\": TB_arr,\n",
    "            \"S_final\": S_final,\n",
    "            \"R_final\": R_final,\n",
    "            \"I_final\": I_final,\n",
    "            \"C_final\": C_final\n",
    "        }\n",
    "    else:\n",
    "        raise RuntimeError(\"Nie można wczytać ani wygenerować danych PDE\")\n",
    "\n",
    "pde_ref = load_or_generate_pde_reference(T=6.0, N=64)\n",
    "t_pde = pde_ref[\"t\"]\n",
    "TB_pde = pde_ref[\"TB\"]\n",
    "\n",
    "print(f\"[OK] Dane PDE: {len(t_pde)} punktów czasowych, t ∈ [{t_pde[0]:.2f}, {t_pde[-1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b06be7",
   "metadata": {},
   "source": [
    "## 4. Symulacja ODE z kalibrowanymi parametrami\n",
    "\n",
    "Używamy parametrów ODE dopasowanych w Zadaniu 3/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e098c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# TODO: Jeśli masz skalibrowane parametry z Zadania 5 (asymilacja),\n",
    "# wczytaj je tutaj. W przeciwnym razie użyj wartości domyślnych.\n",
    "\n",
    "# Próba wczytania z JSON\n",
    "calib_file = \"out/assimilation_abc_ode_params.json\"\n",
    "if Path(calib_file).exists():\n",
    "    with open(calib_file, \"r\") as f:\n",
    "        calib_data = json.load(f)\n",
    "    p_ode = ODEParams(**calib_data)\n",
    "    print(f\"[OK] Wczytano skalibrowane parametry ODE z {calib_file}\")\n",
    "else:\n",
    "    p_ode = ODEParams()\n",
    "    print(\"[INFO] Używam domyślnych parametrów ODE\")\n",
    "\n",
    "# Warunki początkowe ODE\n",
    "y0_ode = np.array([0.8, 0.2, 0.0, 0.0])  # [S, R, I, C]\n",
    "\n",
    "# Symulacja ODE\n",
    "ode_traj = simulate_ode(p_ode, y0_ode, t_pde)\n",
    "TB_ode = ode_traj[\"TB\"]\n",
    "\n",
    "print(f\"[OK] Symulacja ODE zakończona\")\n",
    "print(f\"     RMSE(ODE vs PDE): {rmse(TB_ode, TB_pde):.6f}\")\n",
    "print(f\"     MAE(ODE vs PDE):  {mae(TB_ode, TB_pde):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2387937",
   "metadata": {},
   "source": [
    "## 5. SUPERMODEL — Definicja\n",
    "\n",
    "Supermodel = ODE + neuronowa korekta g_φ(y, t)\n",
    "\n",
    "ẏ(t) = f_ODE(y; θ_calib) + g_φ(y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5748b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CorrectionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Mała sieć neuronowa do korekcji ODE.\n",
    "    Wejście: [S, R, I, C, t] (5-wymiarowy)\n",
    "    Wyjście: [dS, dR, dI, dC] (korekta dla każdej zmiennej)\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim=4, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Wejście: stan + czas\n",
    "        input_dim = state_dim + 1\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        # Warstwy ukryte\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "\n",
    "        # Wyjście: korekta dla każdej zmiennej stanu\n",
    "        layers.append(nn.Linear(hidden_dim, state_dim))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        # Inicjalizacja wagami o małej skali\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        \"\"\"\n",
    "        y: [batch, 4] - stan [S, R, I, C]\n",
    "        t: [batch, 1] - czas\n",
    "        Returns: [batch, 4] - korekta\n",
    "        \"\"\"\n",
    "        inp = torch.cat([y, t], dim=1)\n",
    "        return self.net(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac96c5",
   "metadata": {},
   "source": [
    "## 6. SUPERMODEL — Integrator ODE w PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afcbcd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SupermodelIntegrator:\n",
    "    \"\"\"\n",
    "    Integruje ODE z korektą neuronową używając metody Eulera/RK4.\n",
    "    \"\"\"\n",
    "    def __init__(self, ode_params: ODEParams, correction_net: CorrectionNetwork,\n",
    "                 device=\"cpu\", method=\"euler\"):\n",
    "        self.p = ode_params\n",
    "        self.g_net = correction_net\n",
    "        self.device = device\n",
    "        self.method = method\n",
    "\n",
    "    def ode_rhs_torch(self, t_val, y_tensor):\n",
    "        \"\"\"\n",
    "        Prawa strona ODE w PyTorch (bez korekty).\n",
    "        t_val: skalar (float)\n",
    "        y_tensor: [batch, 4]\n",
    "        Returns: [batch, 4]\n",
    "        \"\"\"\n",
    "        S = y_tensor[:, 0:1]\n",
    "        R = y_tensor[:, 1:2]\n",
    "        I = y_tensor[:, 2:3]\n",
    "        C = y_tensor[:, 3:4]\n",
    "\n",
    "        N = S + R\n",
    "\n",
    "        # Wzrost\n",
    "        dS = self.p.rho_S * S * (1 - N / self.p.K)\n",
    "        dR = self.p.rho_R * R * (1 - N / self.p.K)\n",
    "\n",
    "        # Cytotoksyczność\n",
    "        dS = dS - self.p.alpha_S * C * S - self.p.gamma_S * I * S\n",
    "        dR = dR - self.p.alpha_R * C * R - self.p.gamma_R * I * R\n",
    "\n",
    "        # Oporność (funkcja Hill)\n",
    "        C_np = C.detach().cpu().numpy()\n",
    "        mu_np = mu_of_C(C_np, self.p.mu_max, self.p.C50, self.p.m_hill)\n",
    "        mu = torch.tensor(mu_np, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        dS = dS - mu * S\n",
    "        dR = dR + mu * S\n",
    "\n",
    "        # Immunologia\n",
    "        dI = self.p.sigma * N - self.p.delta * I\n",
    "\n",
    "        # Lek\n",
    "        dC = -self.p.lam * C - self.p.beta * C * N\n",
    "\n",
    "        # Dawkowanie\n",
    "        if self.p.dose_type == \"infusion_const\":\n",
    "            dC = dC + self.p.infusion_rate\n",
    "        elif self.p.dose_type == \"bolus_periodic\":\n",
    "            I_in = dosing_term_exact(t_val, 0.01, self.p.dose_period, self.p.dose_A)\n",
    "            dC = dC + I_in\n",
    "\n",
    "        return torch.cat([dS, dR, dI, dC], dim=1)\n",
    "\n",
    "    def rhs_with_correction(self, t_val, y_tensor):\n",
    "        \"\"\"\n",
    "        Pełna prawa strona: ODE + korekta neuronowa.\n",
    "        \"\"\"\n",
    "        f_ode = self.ode_rhs_torch(t_val, y_tensor)\n",
    "\n",
    "        t_tensor = torch.full((y_tensor.shape[0], 1), t_val,\n",
    "                             dtype=torch.float32, device=self.device)\n",
    "        g_corr = self.g_net(y_tensor, t_tensor)\n",
    "\n",
    "        return f_ode + g_corr\n",
    "\n",
    "    def integrate(self, y0, t_grid):\n",
    "        \"\"\"\n",
    "        Integruje Supermodel na siatce czasowej t_grid.\n",
    "        y0: [4] - warunek początkowy\n",
    "        t_grid: array of time points\n",
    "        Returns: [len(t_grid), 4]\n",
    "        \"\"\"\n",
    "        y0_tensor = torch.tensor(y0, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "\n",
    "        trajectory = [y0_tensor.detach().cpu().numpy()[0]]\n",
    "        y_current = y0_tensor\n",
    "\n",
    "        for i in range(len(t_grid) - 1):\n",
    "            t = t_grid[i]\n",
    "            dt = t_grid[i + 1] - t\n",
    "\n",
    "            if self.method == \"euler\":\n",
    "                # Metoda Eulera\n",
    "                dydt = self.rhs_with_correction(t, y_current)\n",
    "                y_next = y_current + dt * dydt\n",
    "            elif self.method == \"rk4\":\n",
    "                # Runge-Kutta 4. rzędu\n",
    "                k1 = self.rhs_with_correction(t, y_current)\n",
    "                k2 = self.rhs_with_correction(t + 0.5*dt, y_current + 0.5*dt*k1)\n",
    "                k3 = self.rhs_with_correction(t + 0.5*dt, y_current + 0.5*dt*k2)\n",
    "                k4 = self.rhs_with_correction(t + dt, y_current + dt*k3)\n",
    "                y_next = y_current + (dt/6.0) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {self.method}\")\n",
    "\n",
    "            # Clipowanie do wartości nieujemnych\n",
    "            y_next = torch.clamp(y_next, min=0.0)\n",
    "\n",
    "            y_current = y_next\n",
    "            trajectory.append(y_current.detach().cpu().numpy()[0])\n",
    "\n",
    "        return np.array(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b804e",
   "metadata": {},
   "source": [
    "## 7. SUPERMODEL — Trenowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supermodel(correction_net, p_ode, y0, t_target, TB_target,\n",
    "                    epochs=3000, lr=1e-3, reg_weight=0.0, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Trenuje sieć korekcyjną g_φ tak, aby TB_supermodel(t) ≈ TB_target(t).\n",
    "\n",
    "    Parametry:\n",
    "    - correction_net: instancja CorrectionNetwork\n",
    "    - p_ode: parametry ODE\n",
    "    - y0: warunek początkowy [4]\n",
    "    - t_target: array czasów\n",
    "    - TB_target: array wartości TB(t) z PDE\n",
    "    - epochs: liczba epok treningu\n",
    "    - lr: learning rate\n",
    "    - reg_weight: waga regularyzacji (kara za duże korekcje)\n",
    "    - device: \"cuda\" lub \"cpu\"\n",
    "\n",
    "    Zwraca:\n",
    "    - trained_net: wytrenowana sieć\n",
    "    - losses: historia strat\n",
    "    \"\"\"\n",
    "    correction_net = correction_net.to(device)\n",
    "    optimizer = optim.Adam(correction_net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=200)\n",
    "\n",
    "    integrator = SupermodelIntegrator(p_ode, correction_net, device=device, method=\"rk4\")\n",
    "\n",
    "    TB_target_tensor = torch.tensor(TB_target, dtype=torch.float32, device=device)\n",
    "\n",
    "    losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience_limit = 500\n",
    "\n",
    "    print(\"[Supermodel] Start treningu...\")\n",
    "\n",
    "    # Progress bar\n",
    "    epoch_iter = trange(epochs, desc=\"Supermodel\") if TQDM_AVAILABLE else range(epochs)\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Integracja\n",
    "        traj = integrator.integrate(y0, t_target)\n",
    "        TB_pred = traj[:, 0] + traj[:, 1]  # S + R\n",
    "        TB_pred_tensor = torch.tensor(TB_pred, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Strata MSE\n",
    "        loss_mse = torch.mean((TB_pred_tensor - TB_target_tensor)**2)\n",
    "\n",
    "        # Regularyzacja (opcjonalnie)\n",
    "        loss_reg = 0.0\n",
    "        if reg_weight > 0.0:\n",
    "            for param in correction_net.parameters():\n",
    "                loss_reg += torch.sum(param**2)\n",
    "            loss_reg = reg_weight * loss_reg\n",
    "\n",
    "        loss = loss_mse + loss_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Fix warning: detach loss before passing to scheduler\n",
    "        scheduler.step(loss.detach())\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        losses.append(loss_val)\n",
    "\n",
    "        # Early stopping\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience_limit:\n",
    "            if TQDM_AVAILABLE:\n",
    "                epoch_iter.close()\n",
    "            print(f\"[Supermodel] Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        # Update progress bar\n",
    "        if TQDM_AVAILABLE:\n",
    "            epoch_iter.set_postfix({\"loss\": f\"{loss_val:.6f}\", \"mse\": f\"{loss_mse.item():.6f}\"})\n",
    "        elif (epoch + 1) % 500 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{epochs}, Loss: {loss_val:.6f}, \"\n",
    "                  f\"MSE: {loss_mse.item():.6f}\")\n",
    "\n",
    "    print(f\"[Supermodel] Trening zakończony. Finalna strata: {losses[-1]:.6f}\")\n",
    "\n",
    "    return correction_net, losses\n",
    "\n",
    "# Inicjalizacja sieci korekcyjnej\n",
    "correction_net = CorrectionNetwork(state_dim=4, hidden_dim=64, num_layers=2)\n",
    "print(f\"[Supermodel] Sieć korekcyjna: {sum(p.numel() for p in correction_net.parameters())} parametrów\")\n",
    "\n",
    "# Trenowanie\n",
    "correction_net, train_losses = train_supermodel(\n",
    "    correction_net, p_ode, y0_ode, t_pde, TB_pde,\n",
    "    epochs=3000, lr=1e-3, reg_weight=1e-6, device=device\n",
    ")\n",
    "\n",
    "# Zapisz model\n",
    "torch.save(correction_net.state_dict(), \"out/supermodel_correction_net.pt\")\n",
    "print(\"[OK] Model Supermodel zapisany do out/supermodel_correction_net.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d47aa2",
   "metadata": {},
   "source": [
    "## 8. SUPERMODEL — Ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebe34b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Symulacja Supermodel\n",
    "integrator = SupermodelIntegrator(p_ode, correction_net, device=device, method=\"rk4\")\n",
    "traj_supermodel = integrator.integrate(y0_ode, t_pde)\n",
    "TB_supermodel = traj_supermodel[:, 0] + traj_supermodel[:, 1]\n",
    "\n",
    "# Metryki\n",
    "metrics_supermodel = {\n",
    "    \"ODE_vs_PDE\": {\n",
    "        \"RMSE\": float(rmse(TB_ode, TB_pde)),\n",
    "        \"MAE\": float(mae(TB_ode, TB_pde))\n",
    "    },\n",
    "    \"Supermodel_vs_PDE\": {\n",
    "        \"RMSE\": float(rmse(TB_supermodel, TB_pde)),\n",
    "        \"MAE\": float(mae(TB_supermodel, TB_pde))\n",
    "    },\n",
    "    \"Supermodel_vs_ODE\": {\n",
    "        \"RMSE\": float(rmse(TB_supermodel, TB_ode)),\n",
    "        \"MAE\": float(mae(TB_supermodel, TB_ode))\n",
    "    }\n",
    "}\n",
    "\n",
    "save_json(metrics_supermodel, \"supermodel_metrics.json\")\n",
    "\n",
    "# Zapisz trajektorie\n",
    "df_traj = pd.DataFrame({\n",
    "    \"t\": t_pde,\n",
    "    \"TB_pde\": TB_pde,\n",
    "    \"TB_ode\": TB_ode,\n",
    "    \"TB_supermodel\": TB_supermodel\n",
    "})\n",
    "save_csv(df_traj, \"supermodel_tb_curves.csv\")\n",
    "\n",
    "# Wykres\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t_pde, TB_pde, 'k-', lw=2, label=\"PDE (reference)\")\n",
    "plt.plot(t_pde, TB_ode, 'b--', lw=2, label=\"ODE (calibrated)\")\n",
    "plt.plot(t_pde, TB_supermodel, 'r-', lw=2, alpha=0.8, label=\"Supermodel (ODE + NN correction)\")\n",
    "plt.xlabel(\"Czas t\", fontsize=12)\n",
    "plt.ylabel(\"Tumor Burden TB(t)\", fontsize=12)\n",
    "plt.title(\"Porównanie: PDE vs ODE vs Supermodel\", fontsize=13)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "savefig_fig(\"supermodel_tb_compare.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[Supermodel] Metryki:\")\n",
    "for model, metrics in metrics_supermodel.items():\n",
    "    print(f\"  {model}: RMSE={metrics['RMSE']:.6f}, MAE={metrics['MAE']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecb6d4",
   "metadata": {},
   "source": [
    "## 9. SUPERNET — Definicja\n",
    "\n",
    "SuperNet rozszerza PINN o dodatkowy parametr terapii p_dose.\n",
    "Wejście: (x, y, t, p_dose)\n",
    "Wyjście: [Ŝ, R̂, Î, Ĉ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3f9c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class InputNormalizer:\n",
    "    \"\"\"Normalizacja wejść do sieci\"\"\"\n",
    "    def __init__(self, x_range=(0, 1), y_range=(0, 1), t_range=(0, 6), p_range=(0.5, 1.5)):\n",
    "        self.x_range = x_range\n",
    "        self.y_range = y_range\n",
    "        self.t_range = t_range\n",
    "        self.p_range = p_range\n",
    "\n",
    "    def normalize(self, x, y, t, p):\n",
    "        \"\"\"Normalizuje wszystkie wejścia do [-1, 1]\"\"\"\n",
    "        x_n = 2 * (x - self.x_range[0]) / (self.x_range[1] - self.x_range[0]) - 1\n",
    "        y_n = 2 * (y - self.y_range[0]) / (self.y_range[1] - self.y_range[0]) - 1\n",
    "        t_n = 2 * (t - self.t_range[0]) / (self.t_range[1] - self.t_range[0]) - 1\n",
    "        p_n = 2 * (p - self.p_range[0]) / (self.p_range[1] - self.p_range[0]) - 1\n",
    "        return x_n, y_n, t_n, p_n\n",
    "\n",
    "# Skale wyjściowe\n",
    "OUT_SCALE = {\"S\": 1.0, \"R\": 1.0, \"I\": 0.5, \"C\": 0.5}\n",
    "\n",
    "class SuperNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Rozszerzony PINN z dodatkowym parametrem p_dose.\n",
    "    Wejście: (x, y, t, p_dose)\n",
    "    Wyjście: [S, R, I, C]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=4, out_dim=4, width=128, depth=6):\n",
    "        super().__init__()\n",
    "        self.normalizer = InputNormalizer()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(in_dim, width))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.Tanh())\n",
    "\n",
    "        layers.append(nn.Linear(width, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, x, y, t, p):\n",
    "        \"\"\"\n",
    "        x, y, t, p: tensory [N, 1]\n",
    "        Returns: S, R, I, C - każde [N, 1]\n",
    "        \"\"\"\n",
    "        xn, yn, tn, pn = self.normalizer.normalize(x, y, t, p)\n",
    "        inp = torch.cat([xn, yn, tn, pn], dim=1)\n",
    "\n",
    "        raw = self.net(inp)\n",
    "\n",
    "        # Softplus dla nieujemności\n",
    "        S = self.softplus(raw[:, 0:1]) * OUT_SCALE[\"S\"]\n",
    "        R = self.softplus(raw[:, 1:2]) * OUT_SCALE[\"R\"]\n",
    "        I = self.softplus(raw[:, 2:3]) * OUT_SCALE[\"I\"]\n",
    "        C = self.softplus(raw[:, 3:4]) * OUT_SCALE[\"C\"]\n",
    "\n",
    "        return S, R, I, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0b849",
   "metadata": {},
   "source": [
    "## 10. SUPERNET — Generowanie danych treningowych\n",
    "\n",
    "Generujemy dane dla kilku wartości p_dose: {0.5, 1.0, 1.5}\n",
    "Każda wartość odpowiada innej intensywności terapii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a2ce7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_pde_data_for_dose(p_dose, T=6.0, N=64, base_infusion=0.15):\n",
    "    \"\"\"\n",
    "    Generuje dane PDE dla danej wartości p_dose.\n",
    "    p_dose - skalar skalujący infusion_rate (0.5 = słaba, 1.0 = nominalna, 1.5 = silna)\n",
    "\n",
    "    Zwraca: dict {\"t\": array, \"TB\": array, \"snapshots\": list of dicts}\n",
    "    \"\"\"\n",
    "    if not PDE_OK:\n",
    "        raise RuntimeError(\"Moduł PDE nie jest dostępny\")\n",
    "\n",
    "    grid = Grid(Nx=N, Ny=N)\n",
    "    p = copy.deepcopy(p_pde_base)\n",
    "    p.dose_type = \"infusion_const\"\n",
    "    p.infusion_rate = base_infusion * p_dose\n",
    "\n",
    "    dt = 0.01\n",
    "\n",
    "    (S_final, R_final, I_final, C_final), traj, info = run_simulation(\"semi_implicit\", grid, p, T=T, dt=dt, save_every=50)\n",
    "\n",
    "    t_arr = np.array([rec[\"t\"] for rec in traj])\n",
    "    TB_arr = np.array([rec[\"tumor_burden\"] for rec in traj])\n",
    "\n",
    "    # Snapshoty w wybranych czasach (np. t=2, 4, 6)\n",
    "    snapshot_times = [2.0, 4.0, 6.0]\n",
    "    snapshots = []\n",
    "\n",
    "    for t_snap in snapshot_times:\n",
    "        # Znajdź najbliższy punkt czasowy\n",
    "        idx = np.argmin(np.abs(t_arr - t_snap))\n",
    "\n",
    "        # Wygeneruj ponownie do tego czasu (lub użyj zapisanych pól)\n",
    "        # W uproszczeniu użyjemy finalnych pól dla t=6\n",
    "        if abs(t_arr[idx] - T) < 0.1:\n",
    "            snapshots.append({\n",
    "                \"t\": T,\n",
    "                \"S\": S_final.copy(),\n",
    "                \"R\": R_final.copy(),\n",
    "                \"I\": I_final.copy(),\n",
    "                \"C\": C_final.copy()\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"t\": t_arr,\n",
    "        \"TB\": TB_arr,\n",
    "        \"snapshots\": snapshots,\n",
    "        \"grid\": grid\n",
    "    }\n",
    "\n",
    "# Generowanie danych dla różnych dawek\n",
    "dose_scenarios = [0.5, 1.0, 1.5]\n",
    "pde_data_scenarios = {}\n",
    "\n",
    "print(\"\\n[SuperNet] Generowanie danych PDE dla różnych scenariuszy...\")\n",
    "for p_dose in dose_scenarios:\n",
    "    print(f\"  Scenariusz p_dose = {p_dose}...\")\n",
    "    pde_data_scenarios[p_dose] = generate_pde_data_for_dose(p_dose, T=6.0, N=64)\n",
    "    print(f\"    -> TB(T={pde_data_scenarios[p_dose]['t'][-1]:.2f}) = \"\n",
    "          f\"{pde_data_scenarios[p_dose]['TB'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ecffb",
   "metadata": {},
   "source": [
    "## 11. SUPERNET — Przygotowanie danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6000e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_supernet_training_data(pde_data_scenarios, n_collocation=2000, n_ic=500, n_bc=500):\n",
    "    \"\"\"\n",
    "    Przygotowuje dane treningowe dla SuperNet.\n",
    "\n",
    "    Zwraca:\n",
    "    - collocation_points: punkty (x,y,t,p) do residual loss\n",
    "    - ic_data: warunki początkowe (x,y,0,p) -> wartości pól\n",
    "    - bc_data: warunki brzegowe\n",
    "    - tb_data: trajektorie TB(t,p)\n",
    "    \"\"\"\n",
    "    # Punkty kolokacyjne (równomiernie w (x,y,t,p))\n",
    "    grid_sample = pde_data_scenarios[1.0][\"grid\"]  # użyj siatki nominalnej\n",
    "\n",
    "    collocation = []\n",
    "    for p_dose in dose_scenarios:\n",
    "        for _ in range(n_collocation // len(dose_scenarios)):\n",
    "            x = np.random.uniform(0, grid_sample.Lx)\n",
    "            y = np.random.uniform(0, grid_sample.Ly)\n",
    "            t = np.random.uniform(0, 6.0)\n",
    "            collocation.append([x, y, t, p_dose])\n",
    "\n",
    "    collocation = np.array(collocation)\n",
    "\n",
    "    # Warunki początkowe (t=0)\n",
    "    ic_data = {\"points\": [], \"values\": []}\n",
    "    for p_dose in dose_scenarios:\n",
    "        grid = pde_data_scenarios[p_dose][\"grid\"]\n",
    "        X, Y = grid.X, grid.Y\n",
    "\n",
    "        # Losowo wybierz n_ic punktów\n",
    "        idx = np.random.choice(X.size, size=n_ic // len(dose_scenarios), replace=False)\n",
    "        x_ic = X.ravel()[idx]\n",
    "        y_ic = Y.ravel()[idx]\n",
    "        t_ic = np.zeros_like(x_ic)\n",
    "        p_ic = np.full_like(x_ic, p_dose)\n",
    "\n",
    "        # TODO: Wartości początkowe - tutaj używamy uproszczonej inicjalizacji\n",
    "        # W pełnej wersji użyj init_fields z modułu PDE\n",
    "        S_ic = 0.8 * np.exp(-((x_ic - 0.5)**2 + (y_ic - 0.5)**2) / 0.04)\n",
    "        R_ic = 0.2 * np.exp(-((x_ic - 0.5)**2 + (y_ic - 0.5)**2) / 0.04)\n",
    "        I_ic = np.zeros_like(x_ic)\n",
    "        C_ic = np.zeros_like(x_ic)\n",
    "\n",
    "        for i in range(len(x_ic)):\n",
    "            ic_data[\"points\"].append([x_ic[i], y_ic[i], t_ic[i], p_ic[i]])\n",
    "            ic_data[\"values\"].append([S_ic[i], R_ic[i], I_ic[i], C_ic[i]])\n",
    "\n",
    "    ic_data[\"points\"] = np.array(ic_data[\"points\"])\n",
    "    ic_data[\"values\"] = np.array(ic_data[\"values\"])\n",
    "\n",
    "    # Trajektorie TB(t)\n",
    "    tb_data = {\"t\": [], \"p\": [], \"TB\": []}\n",
    "    for p_dose in dose_scenarios:\n",
    "        t_arr = pde_data_scenarios[p_dose][\"t\"]\n",
    "        TB_arr = pde_data_scenarios[p_dose][\"TB\"]\n",
    "\n",
    "        for i in range(len(t_arr)):\n",
    "            tb_data[\"t\"].append(t_arr[i])\n",
    "            tb_data[\"p\"].append(p_dose)\n",
    "            tb_data[\"TB\"].append(TB_arr[i])\n",
    "\n",
    "    tb_data[\"t\"] = np.array(tb_data[\"t\"])\n",
    "    tb_data[\"p\"] = np.array(tb_data[\"p\"])\n",
    "    tb_data[\"TB\"] = np.array(tb_data[\"TB\"])\n",
    "\n",
    "    return {\n",
    "        \"collocation\": collocation,\n",
    "        \"ic\": ic_data,\n",
    "        \"tb\": tb_data\n",
    "    }\n",
    "\n",
    "training_data = prepare_supernet_training_data(pde_data_scenarios)\n",
    "print(f\"\\n[SuperNet] Dane treningowe przygotowane:\")\n",
    "print(f\"  Punkty kolokacyjne: {len(training_data['collocation'])}\")\n",
    "print(f\"  Warunki początkowe: {len(training_data['ic']['points'])}\")\n",
    "print(f\"  Punkty TB(t): {len(training_data['tb']['t'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563114f6",
   "metadata": {},
   "source": [
    "## 12. SUPERNET — Funkcje straty (PDE residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8d8c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_pde_residuals(supernet, x, y, t, p, params):\n",
    "    \"\"\"\n",
    "    Oblicza residua równań PDE.\n",
    "    Zwraca: res_S, res_R, res_I, res_C (każde [N, 1])\n",
    "    \"\"\"\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "\n",
    "    S, R, I, C = supernet(x, y, t, p)\n",
    "\n",
    "    # Pochodne czasowe\n",
    "    S_t = torch.autograd.grad(S, t, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
    "    R_t = torch.autograd.grad(R, t, grad_outputs=torch.ones_like(R), create_graph=True)[0]\n",
    "    I_t = torch.autograd.grad(I, t, grad_outputs=torch.ones_like(I), create_graph=True)[0]\n",
    "    C_t = torch.autograd.grad(C, t, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
    "\n",
    "    # Pochodne przestrzenne (laplacian)\n",
    "    S_x = torch.autograd.grad(S, x, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
    "    S_xx = torch.autograd.grad(S_x, x, grad_outputs=torch.ones_like(S_x), create_graph=True)[0]\n",
    "    S_y = torch.autograd.grad(S, y, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
    "    S_yy = torch.autograd.grad(S_y, y, grad_outputs=torch.ones_like(S_y), create_graph=True)[0]\n",
    "\n",
    "    R_x = torch.autograd.grad(R, x, grad_outputs=torch.ones_like(R), create_graph=True)[0]\n",
    "    R_xx = torch.autograd.grad(R_x, x, grad_outputs=torch.ones_like(R_x), create_graph=True)[0]\n",
    "    R_y = torch.autograd.grad(R, y, grad_outputs=torch.ones_like(R), create_graph=True)[0]\n",
    "    R_yy = torch.autograd.grad(R_y, y, grad_outputs=torch.ones_like(R_y), create_graph=True)[0]\n",
    "\n",
    "    I_x = torch.autograd.grad(I, x, grad_outputs=torch.ones_like(I), create_graph=True)[0]\n",
    "    I_xx = torch.autograd.grad(I_x, x, grad_outputs=torch.ones_like(I_x), create_graph=True)[0]\n",
    "    I_y = torch.autograd.grad(I, y, grad_outputs=torch.ones_like(I), create_graph=True)[0]\n",
    "    I_yy = torch.autograd.grad(I_y, y, grad_outputs=torch.ones_like(I_y), create_graph=True)[0]\n",
    "\n",
    "    C_x = torch.autograd.grad(C, x, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
    "    C_xx = torch.autograd.grad(C_x, x, grad_outputs=torch.ones_like(C_x), create_graph=True)[0]\n",
    "    C_y = torch.autograd.grad(C, y, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
    "    C_yy = torch.autograd.grad(C_y, y, grad_outputs=torch.ones_like(C_y), create_graph=True)[0]\n",
    "\n",
    "    # Parametry (użyj wartości z p_pde_base)\n",
    "    D_S = params.get(\"D_S\", 0.0)\n",
    "    D_R = params.get(\"D_R\", 0.0)\n",
    "    D_I = params.get(\"D_I\", 0.0)\n",
    "    D_C = params.get(\"D_C\", 0.01)\n",
    "\n",
    "    rho_S = params.get(\"rho_S\", 0.04)\n",
    "    rho_R = params.get(\"rho_R\", 0.03)\n",
    "    K = params.get(\"K\", 1.0)\n",
    "    alpha_S = params.get(\"alpha_S\", 0.8)\n",
    "    alpha_R = params.get(\"alpha_R\", 0.1)\n",
    "    gamma_S = params.get(\"gamma_S\", 0.02)\n",
    "    gamma_R = params.get(\"gamma_R\", 0.02)\n",
    "    sigma = params.get(\"sigma\", 0.05)\n",
    "    delta = params.get(\"delta\", 0.1)\n",
    "    lam = params.get(\"lam\", 0.2)\n",
    "    beta = params.get(\"beta\", 0.0)\n",
    "    mu_max = params.get(\"mu_max\", 0.05)\n",
    "    C50 = params.get(\"C50\", 0.2)\n",
    "    m_hill = params.get(\"m_hill\", 3)\n",
    "\n",
    "    # Reakcje\n",
    "    N = S + R\n",
    "\n",
    "    # Funkcja Hill (oporność)\n",
    "    C_np = C.detach().cpu().numpy()\n",
    "    mu_np = mu_of_C(C_np, mu_max, C50, m_hill)\n",
    "    mu = torch.tensor(mu_np, dtype=torch.float32, device=C.device)\n",
    "\n",
    "    # Równania PDE\n",
    "    # S: ∂S/∂t = D_S∇²S + rho_S*S*(1-N/K) - alpha_S*C*S - gamma_S*I*S - mu*S\n",
    "    res_S = S_t - D_S * (S_xx + S_yy) - (\n",
    "        rho_S * S * (1 - N / K) - alpha_S * C * S - gamma_S * I * S - mu * S\n",
    "    )\n",
    "\n",
    "    # R: ∂R/∂t = D_R∇²R + rho_R*R*(1-N/K) - alpha_R*C*R - gamma_R*I*R + mu*S\n",
    "    res_R = R_t - D_R * (R_xx + R_yy) - (\n",
    "        rho_R * R * (1 - N / K) - alpha_R * C * R - gamma_R * I * R + mu * S\n",
    "    )\n",
    "\n",
    "    # I: ∂I/∂t = D_I∇²I + sigma*N - delta*I\n",
    "    res_I = I_t - D_I * (I_xx + I_yy) - (sigma * N - delta * I)\n",
    "\n",
    "    # C: ∂C/∂t = D_C∇²C - lam*C - beta*C*N + I_in(p)\n",
    "    # I_in zależy od p (p * base_infusion_rate)\n",
    "    base_infusion = 0.15\n",
    "    I_in = p * base_infusion\n",
    "\n",
    "    res_C = C_t - D_C * (C_xx + C_yy) - (-lam * C - beta * C * N + I_in)\n",
    "\n",
    "    return res_S, res_R, res_I, res_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ee6fe",
   "metadata": {},
   "source": [
    "## 13. SUPERNET — Trenowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa516d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_supernet(supernet, training_data, pde_params, epochs=5000, lr=1e-3,\n",
    "                  batch_size=512, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Trenuje SuperNet na danych z wielu scenariuszy.\n",
    "\n",
    "    Straty:\n",
    "    - PDE residuals (fizyka)\n",
    "    - Initial conditions\n",
    "    - TB trajectory matching\n",
    "    \"\"\"\n",
    "    supernet = supernet.to(device)\n",
    "    optimizer = optim.Adam(supernet.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=300)\n",
    "\n",
    "    # Dane treningowe\n",
    "    coll_pts = training_data[\"collocation\"]\n",
    "    ic_pts = training_data[\"ic\"][\"points\"]\n",
    "    ic_vals = training_data[\"ic\"][\"values\"]\n",
    "    tb_t = training_data[\"tb\"][\"t\"]\n",
    "    tb_p = training_data[\"tb\"][\"p\"]\n",
    "    tb_vals = training_data[\"tb\"][\"TB\"]\n",
    "\n",
    "    # Przelicz parametry PDE na słownik\n",
    "    pde_params_dict = asdict(pde_params) if hasattr(pde_params, '__dataclass_fields__') else pde_params\n",
    "\n",
    "    losses_hist = []\n",
    "\n",
    "    print(\"\\n[SuperNet] Start treningu...\")\n",
    "\n",
    "    # Progress bar\n",
    "    epoch_iter = trange(epochs, desc=\"SuperNet\") if TQDM_AVAILABLE else range(epochs)\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # === 1. PDE Residuals ===\n",
    "        # Losuj batch punktów kolokacyjnych\n",
    "        idx_coll = np.random.choice(len(coll_pts), size=min(batch_size, len(coll_pts)), replace=False)\n",
    "        batch_coll = coll_pts[idx_coll]\n",
    "\n",
    "        x_coll = torch.tensor(batch_coll[:, 0:1], dtype=torch.float32, device=device)\n",
    "        y_coll = torch.tensor(batch_coll[:, 1:2], dtype=torch.float32, device=device)\n",
    "        t_coll = torch.tensor(batch_coll[:, 2:3], dtype=torch.float32, device=device)\n",
    "        p_coll = torch.tensor(batch_coll[:, 3:4], dtype=torch.float32, device=device)\n",
    "\n",
    "        res_S, res_R, res_I, res_C = compute_pde_residuals(supernet, x_coll, y_coll, t_coll,\n",
    "                                                           p_coll, pde_params_dict)\n",
    "\n",
    "        loss_pde = torch.mean(res_S**2 + res_R**2 + res_I**2 + res_C**2)\n",
    "\n",
    "        # === 2. Initial Conditions ===\n",
    "        idx_ic = np.random.choice(len(ic_pts), size=min(batch_size//2, len(ic_pts)), replace=False)\n",
    "        batch_ic_pts = ic_pts[idx_ic]\n",
    "        batch_ic_vals = ic_vals[idx_ic]\n",
    "\n",
    "        x_ic = torch.tensor(batch_ic_pts[:, 0:1], dtype=torch.float32, device=device)\n",
    "        y_ic = torch.tensor(batch_ic_pts[:, 1:2], dtype=torch.float32, device=device)\n",
    "        t_ic = torch.tensor(batch_ic_pts[:, 2:3], dtype=torch.float32, device=device)\n",
    "        p_ic = torch.tensor(batch_ic_pts[:, 3:4], dtype=torch.float32, device=device)\n",
    "\n",
    "        S_ic, R_ic, I_ic, C_ic = supernet(x_ic, y_ic, t_ic, p_ic)\n",
    "\n",
    "        S_ic_true = torch.tensor(batch_ic_vals[:, 0:1], dtype=torch.float32, device=device)\n",
    "        R_ic_true = torch.tensor(batch_ic_vals[:, 1:2], dtype=torch.float32, device=device)\n",
    "        I_ic_true = torch.tensor(batch_ic_vals[:, 2:3], dtype=torch.float32, device=device)\n",
    "        C_ic_true = torch.tensor(batch_ic_vals[:, 3:4], dtype=torch.float32, device=device)\n",
    "\n",
    "        loss_ic = torch.mean((S_ic - S_ic_true)**2 + (R_ic - R_ic_true)**2 +\n",
    "                            (I_ic - I_ic_true)**2 + (C_ic - C_ic_true)**2)\n",
    "\n",
    "        # === 3. TB Trajectory ===\n",
    "        # Dla uproszczenia: próbkujemy punkty na siatce przestrzennej i całkujemy TB\n",
    "        # W pełnej wersji użyj właściwej kwadratury\n",
    "        idx_tb = np.random.choice(len(tb_t), size=min(batch_size//4, len(tb_t)), replace=False)\n",
    "        t_tb_batch = tb_t[idx_tb]\n",
    "        p_tb_batch = tb_p[idx_tb]\n",
    "        TB_true_batch = tb_vals[idx_tb]\n",
    "\n",
    "        # Dla każdego punktu (t, p) oblicz TB przez całkowanie po (x,y)\n",
    "        TB_pred_list = []\n",
    "        for i in range(len(t_tb_batch)):\n",
    "            # Próbkuj punkty przestrzenne\n",
    "            n_spatial = 20\n",
    "            x_samp = np.linspace(0, 1, n_spatial)\n",
    "            y_samp = np.linspace(0, 1, n_spatial)\n",
    "            X_samp, Y_samp = np.meshgrid(x_samp, y_samp)\n",
    "            x_flat = X_samp.ravel()\n",
    "            y_flat = Y_samp.ravel()\n",
    "            t_flat = np.full_like(x_flat, t_tb_batch[i])\n",
    "            p_flat = np.full_like(x_flat, p_tb_batch[i])\n",
    "\n",
    "            x_t = torch.tensor(x_flat.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "            y_t = torch.tensor(y_flat.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "            t_t = torch.tensor(t_flat.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "            p_t = torch.tensor(p_flat.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "            with torch.no_grad():  # oszczędność pamięci\n",
    "                S_samp, R_samp, _, _ = supernet(x_t, y_t, t_t, p_t)\n",
    "\n",
    "            TB_samp = S_samp + R_samp\n",
    "            TB_integral = torch.mean(TB_samp)  # uproszczone całkowanie\n",
    "            TB_pred_list.append(TB_integral)\n",
    "\n",
    "        TB_pred_tensor = torch.stack(TB_pred_list)\n",
    "        TB_true_tensor = torch.tensor(TB_true_batch, dtype=torch.float32, device=device)\n",
    "\n",
    "        loss_tb = torch.mean((TB_pred_tensor - TB_true_tensor)**2)\n",
    "\n",
    "        # === Łączna strata ===\n",
    "        # Wagi dla różnych komponentów (do dostrojenia)\n",
    "        w_pde = 1.0\n",
    "        w_ic = 10.0\n",
    "        w_tb = 100.0\n",
    "\n",
    "        loss = w_pde * loss_pde + w_ic * loss_ic + w_tb * loss_tb\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(supernet.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Fix warning: detach loss before passing to scheduler\n",
    "        scheduler.step(loss.detach())\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        losses_hist.append(loss_val)\n",
    "\n",
    "        # Update progress bar\n",
    "        if TQDM_AVAILABLE:\n",
    "            epoch_iter.set_postfix({\n",
    "                \"loss\": f\"{loss_val:.4f}\",\n",
    "                \"pde\": f\"{loss_pde.item():.4f}\",\n",
    "                \"ic\": f\"{loss_ic.item():.4f}\",\n",
    "                \"tb\": f\"{loss_tb.item():.4f}\"\n",
    "            })\n",
    "        elif (epoch + 1) % 500 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{epochs}, Loss: {loss_val:.6f}, \"\n",
    "                  f\"PDE: {loss_pde.item():.6f}, IC: {loss_ic.item():.6f}, TB: {loss_tb.item():.6f}\")\n",
    "\n",
    "    print(f\"[SuperNet] Trening zakończony. Finalna strata: {losses_hist[-1]:.6f}\")\n",
    "\n",
    "    return supernet, losses_hist\n",
    "\n",
    "# Inicjalizacja SuperNet\n",
    "supernet = SuperNet(in_dim=4, out_dim=4, width=128, depth=6)\n",
    "print(f\"\\n[SuperNet] Parametry sieci: {sum(p.numel() for p in supernet.parameters())/1e6:.2f}M\")\n",
    "\n",
    "# Trenowanie (uwaga: może być czasochłonne)\n",
    "# W produkcji użyj większej liczby epok\n",
    "if PDE_OK:\n",
    "    supernet, supernet_losses = train_supernet(\n",
    "        supernet, training_data, p_pde_base,\n",
    "        epochs=2000, lr=1e-3, batch_size=512, device=device\n",
    "    )\n",
    "\n",
    "    # Zapisz model\n",
    "    torch.save(supernet.state_dict(), \"out/supernet_model.pt\")\n",
    "    print(\"[OK] Model SuperNet zapisany do out/supernet_model.pt\")\n",
    "else:\n",
    "    print(\"[UWAGA] SuperNet nie został wytrenowany - brak modułu PDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1282e0",
   "metadata": {},
   "source": [
    "## 14. SUPERNET — Ewaluacja i porównanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30953175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_supernet_scenario(supernet, grid, t_eval, p_dose, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Ewaluuje SuperNet dla danego scenariusza (p_dose).\n",
    "    Zwraca TB(t) oraz pola w ostatnim czasie.\n",
    "    \"\"\"\n",
    "    supernet.eval()\n",
    "\n",
    "    X, Y = grid.X, grid.Y\n",
    "    TB_over_time = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t_val in t_eval:\n",
    "            x_flat = torch.tensor(X.ravel().reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "            y_flat = torch.tensor(Y.ravel().reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "            t_flat = torch.full_like(x_flat, t_val)\n",
    "            p_flat = torch.full_like(x_flat, p_dose)\n",
    "\n",
    "            S, R, I, C = supernet(x_flat, y_flat, t_flat, p_flat)\n",
    "\n",
    "            S_field = S.cpu().numpy().reshape(X.shape)\n",
    "            R_field = R.cpu().numpy().reshape(X.shape)\n",
    "\n",
    "            # Całka TB = ∫(S+R) dx dy\n",
    "            TB = np.sum(S_field + R_field) * grid.dx * grid.dy\n",
    "            TB_over_time.append(TB)\n",
    "\n",
    "    return np.array(TB_over_time)\n",
    "\n",
    "if PDE_OK:\n",
    "    print(\"\\n[SuperNet] Ewaluacja dla scenariuszy...\")\n",
    "\n",
    "    supernet_metrics = {}\n",
    "    grid_eval = Grid(Nx=64, Ny=64)\n",
    "\n",
    "    for p_dose in dose_scenarios:\n",
    "        print(f\"  Scenariusz p_dose = {p_dose}...\")\n",
    "\n",
    "        # PDE reference\n",
    "        t_ref = pde_data_scenarios[p_dose][\"t\"]\n",
    "        TB_pde_ref = pde_data_scenarios[p_dose][\"TB\"]\n",
    "\n",
    "        # SuperNet\n",
    "        TB_supernet = evaluate_supernet_scenario(supernet, grid_eval, t_ref, p_dose, device)\n",
    "\n",
    "        # ODE (z parametrem p_dose - musimy przeskalować infusion_rate)\n",
    "        p_ode_scaled = copy.deepcopy(p_ode)\n",
    "        p_ode_scaled.infusion_rate = 0.15 * p_dose\n",
    "        ode_traj_scaled = simulate_ode(p_ode_scaled, y0_ode, t_ref)\n",
    "        TB_ode_scaled = ode_traj_scaled[\"TB\"]\n",
    "\n",
    "        # Supermodel (używamy tej samej sieci korekcyjnej - może być nieoptymalne)\n",
    "        integrator_scaled = SupermodelIntegrator(p_ode_scaled, correction_net, device=device, method=\"rk4\")\n",
    "        traj_sm_scaled = integrator_scaled.integrate(y0_ode, t_ref)\n",
    "        TB_supermodel_scaled = traj_sm_scaled[:, 0] + traj_sm_scaled[:, 1]\n",
    "\n",
    "        # Metryki\n",
    "        metrics = {\n",
    "            \"ODE_vs_PDE\": {\n",
    "                \"RMSE\": float(rmse(TB_ode_scaled, TB_pde_ref)),\n",
    "                \"MAE\": float(mae(TB_ode_scaled, TB_pde_ref))\n",
    "            },\n",
    "            \"Supermodel_vs_PDE\": {\n",
    "                \"RMSE\": float(rmse(TB_supermodel_scaled, TB_pde_ref)),\n",
    "                \"MAE\": float(mae(TB_supermodel_scaled, TB_pde_ref))\n",
    "            },\n",
    "            \"SuperNet_vs_PDE\": {\n",
    "                \"RMSE\": float(rmse(TB_supernet, TB_pde_ref)),\n",
    "                \"MAE\": float(mae(TB_supernet, TB_pde_ref))\n",
    "            }\n",
    "        }\n",
    "\n",
    "        supernet_metrics[f\"dose_{p_dose}\"] = metrics\n",
    "\n",
    "        # Wykres\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(t_ref, TB_pde_ref, 'k-', lw=2.5, label=\"PDE (reference)\")\n",
    "        plt.plot(t_ref, TB_ode_scaled, 'b--', lw=2, label=\"ODE\")\n",
    "        plt.plot(t_ref, TB_supermodel_scaled, 'g:', lw=2, label=\"Supermodel\")\n",
    "        plt.plot(t_ref, TB_supernet, 'r-.', lw=2, label=\"SuperNet\")\n",
    "        plt.xlabel(\"Czas t\", fontsize=12)\n",
    "        plt.ylabel(\"Tumor Burden TB(t)\", fontsize=12)\n",
    "        plt.title(f\"Porównanie dla p_dose = {p_dose}\", fontsize=13)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        fname = f\"out/supermodel_supernet_tb_dose{str(p_dose).replace('.', '')}.png\"\n",
    "        savefig_root(fname)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"    RMSE(SuperNet vs PDE): {metrics['SuperNet_vs_PDE']['RMSE']:.6f}\")\n",
    "\n",
    "    # Zapisz metryki\n",
    "    save_json(supernet_metrics, \"supernet_metrics.json\")\n",
    "\n",
    "    print(\"\\n[SuperNet] Podsumowanie metryk:\")\n",
    "    for scenario, metrics in supernet_metrics.items():\n",
    "        print(f\"\\n  {scenario}:\")\n",
    "        for model, vals in metrics.items():\n",
    "            print(f\"    {model}: RMSE={vals['RMSE']:.6f}, MAE={vals['MAE']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc48dfc",
   "metadata": {},
   "source": [
    "## 15. Podsumowanie końcowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb236af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PODSUMOWANIE ZADANIA 7\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[SUPERMODEL]\")\n",
    "print(\"  Model: ODE + neuronowa korekta g_φ(y,t)\")\n",
    "print(f\"  Parametry sieci: {sum(p.numel() for p in correction_net.parameters())}\")\n",
    "print(\"  Zapisane pliki:\")\n",
    "print(\"    - out/supermodel_correction_net.pt\")\n",
    "print(\"    - out/supermodel_metrics.json\")\n",
    "print(\"    - out/supermodel_tb_curves.csv\")\n",
    "print(\"    - out/supermodel_tb_compare.png\")\n",
    "\n",
    "if PDE_OK:\n",
    "    print(\"\\n[SUPERNET]\")\n",
    "    print(\"  Model: PINN rozszerzony o parametr terapii (x,y,t,p)\")\n",
    "    print(f\"  Parametry sieci: {sum(p.numel() for p in supernet.parameters())/1e6:.2f}M\")\n",
    "    print(f\"  Scenariusze treningowe: {dose_scenarios}\")\n",
    "    print(\"  Zapisane pliki:\")\n",
    "    print(\"    - out/supernet_model.pt\")\n",
    "    print(\"    - out/supernet_metrics.json\")\n",
    "    for p_dose in dose_scenarios:\n",
    "        fname = f\"supermodel_supernet_tb_dose{str(p_dose).replace('.', '')}.png\"\n",
    "        print(f\"    - {fname}\")\n",
    "\n",
    "print(\"\\n[METRYKI - Scenariusz nominalny p_dose=1.0]\")\n",
    "if \"Supermodel_vs_PDE\" in metrics_supermodel:\n",
    "    print(f\"  Supermodel vs PDE: RMSE={metrics_supermodel['Supermodel_vs_PDE']['RMSE']:.6f}\")\n",
    "if PDE_OK and \"dose_1.0\" in supernet_metrics:\n",
    "    print(f\"  SuperNet vs PDE:   RMSE={supernet_metrics['dose_1.0']['SuperNet_vs_PDE']['RMSE']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Zadanie 7 zakończone!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5141a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
