{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ffc63c",
   "metadata": {},
   "source": [
    "# Zadanie 6 — PINN dla PDE (porównanie z PDE i ODE)\n",
    "\n",
    "Cel:\n",
    "1) Stworzyć fizycznie informowaną sieć (PINN) aproksymującą pola S(x,y,t), R(x,y,t), I(x,y,t), C(x,y,t).\n",
    "2) Trenować PINN na:\n",
    "   - resztach równań PDE (fizyka),\n",
    "   - warunkach początkowych i brzegowych,\n",
    "   - słabych danych TB(t)=∬(S+R) dxdy z PDE (po asymilacji).\n",
    "3) Porównać predykcję PINN z symulacją PDE oraz z modelem ODE (parametry z asymilacji).\n",
    "Zapisy: figi → `figs/`, dane → `out/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time, random, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Path(\"figs\").mkdir(exist_ok=True)\n",
    "Path(\"out\").mkdir(exist_ok=True)\n",
    "\n",
    "def savefig_fig(name, dpi=160):\n",
    "    if not str(name).startswith(\"figs/\"):\n",
    "        name = f\"figs/{name}\"\n",
    "    plt.savefig(name, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[Zapisano wykres] {name}\")\n",
    "\n",
    "def save_json(obj, path):\n",
    "    if not str(path).startswith(\"out/\"):\n",
    "        path = f\"out/{path}\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    print(f\"[Zapisano JSON] {path}\")\n",
    "\n",
    "# Reproducowalność\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Poprawka: użyj CPU jako fallback zamiast MPS (dla większej kompatybilności)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"[Device] Używam: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7045a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Próba importu Twojego modułu PDE (Zadanie 2)\n",
    "import importlib.util\n",
    "\n",
    "PDE_OK = True\n",
    "try:\n",
    "    candidates = [\"2_tumor_diffusion_pde_analysis.py\"]\n",
    "    pdemod = None\n",
    "    for cand in candidates:\n",
    "        if Path(cand).exists():\n",
    "            spec = importlib.util.spec_from_file_location(\"pdemod\", cand)\n",
    "            pdemod = importlib.util.module_from_spec(spec)\n",
    "            sys.modules[\"pdemod\"] = pdemod\n",
    "            spec.loader.exec_module(pdemod)\n",
    "            break\n",
    "    if pdemod is None:\n",
    "        raise FileNotFoundError(\"Nie znaleziono pliku modułu PDE.\")\n",
    "    Grid = pdemod.Grid\n",
    "    Params = pdemod.Params\n",
    "    run_simulation = pdemod.run_simulation\n",
    "    init_fields = pdemod.init_fields\n",
    "    p_base = pdemod.p\n",
    "    print(\"[OK] Moduł PDE załadowany.\")\n",
    "except Exception as e:\n",
    "    PDE_OK = False\n",
    "    print(\"Uwaga: nie udało się załadować modułu PDE:\", e)\n",
    "\n",
    "# 2) ODE (z Zad. 5) — tylko do porównań TB(t)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ODEParams:\n",
    "    rho_S: float = 0.04\n",
    "    rho_R: float = 0.03\n",
    "    K: float = 1.0\n",
    "    alpha_S: float = 0.8\n",
    "    alpha_R: float = 0.12\n",
    "    sigma: float = 0.05\n",
    "    delta: float = 0.1\n",
    "    gamma_S: float = 0.02\n",
    "    gamma_R: float = 0.02\n",
    "    lam: float = 0.2\n",
    "    beta: float = 0.0\n",
    "    mu_max: float = 0.05\n",
    "    C50: float = 0.2\n",
    "    m_hill: int = 3\n",
    "    dose_type: str = \"bolus_periodic\"\n",
    "    dose_A: float = 1.0\n",
    "    dose_period: float = 5.0\n",
    "    infusion_rate: float = 0.0\n",
    "\n",
    "def mu_of_C(C, mu_max, C50, m):\n",
    "    Cn = max(C, 0.0)\n",
    "    r = (Cn/(C50+1e-12))**m\n",
    "    return mu_max * (r/(1+r))\n",
    "\n",
    "def dosing_term_exact(t, dt, period, A):\n",
    "    tau = 0.01*period\n",
    "    t0 = (t // period) * period\n",
    "    start, end = t0, t0+tau\n",
    "    overlap = max(0.0, min(t+dt, end)-max(t, start))\n",
    "    return (A/tau)*(overlap/max(dt,1e-12))\n",
    "\n",
    "def ode_rhs(t, y, p: ODEParams, dt_for_dose):\n",
    "    S, R, I, C = y\n",
    "    N = S + R\n",
    "    dS = p.rho_S*S*(1-N/p.K) - p.alpha_S*C*S - p.gamma_S*I*S\n",
    "    dR = p.rho_R*R*(1-N/p.K) - p.alpha_R*C*R - p.gamma_R*I*R\n",
    "    dS -= mu_of_C(C, p.mu_max, p.C50, p.m_hill) * S\n",
    "    dR += mu_of_C(C, p.mu_max, p.C50, p.m_hill) * S\n",
    "    dI = p.sigma*N - p.delta*I\n",
    "    dC = -p.lam*C - p.beta*C*N\n",
    "    I_in = dosing_term_exact(t, dt_for_dose, p.dose_period, p.dose_A) if p.dose_type==\"bolus_periodic\" else 0.0\n",
    "    dC += I_in\n",
    "    return np.array([dS,dR,dI,dC], dtype=float)\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "def simulate_ode(p: ODEParams, y0, t_eval):\n",
    "    dt = np.mean(np.diff(t_eval)) if len(t_eval)>1 else 1e-2\n",
    "    fun = lambda t,y: ode_rhs(t,y,p,dt)\n",
    "    sol = solve_ivp(fun, (t_eval[0], t_eval[-1]), y0, t_eval=t_eval, rtol=1e-7, atol=1e-9)\n",
    "    Y = sol.y.T\n",
    "    return {\"t\": t_eval, \"S\": Y[:,0], \"R\": Y[:,1], \"I\": Y[:,2], \"C\": Y[:,3], \"TB\": Y[:,0]+Y[:,1]}\n",
    "\n",
    "# 3) Wczytaj parametry po asymilacji (preferencyjnie 3D-Var large → medium → small; fallback: ABC)\n",
    "def load_assimilated_params():\n",
    "    order = [\"out/3dvar_large_summary.json\", \"out/3dvar_medium_summary.json\", \"out/3dvar_small_summary.json\",\n",
    "             \"out/abc_large_summary.json\", \"out/abc_medium_summary.json\", \"out/abc_small_summary.json\"]\n",
    "    for path in order:\n",
    "        if Path(path).exists():\n",
    "            with open(path, \"r\") as f:\n",
    "                js = json.load(f)\n",
    "            if \"theta_opt\" in js:\n",
    "                alpha_S, mu_max, lam = js[\"theta_opt\"]\n",
    "            else:\n",
    "                alpha_S, mu_max, lam = js[\"theta_map\"]\n",
    "            return float(alpha_S), float(mu_max), float(lam), path\n",
    "    # fallback — bazowe\n",
    "    return p_base.alpha_S, p_base.mu_max, p_base.lam, \"baseline(p_base)\"\n",
    "\n",
    "alpha_S_assim, mu_max_assim, lam_assim, src = load_assimilated_params()\n",
    "print(f\"[PARAMS] Źródło: {src}  →  alpha_S={alpha_S_assim:.3f}, mu_max={mu_max_assim:.3f}, lam={lam_assim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e4ce1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Horyzont i siatki\n",
    "T_end = 6.0\n",
    "Lx, Ly = 1.0, 1.0  # Domena przestrzenna\n",
    "t_eval = np.linspace(0.0, T_end, 121)  # co 0.05\n",
    "Nx_data, Ny_data = 64, 64              # siatka do generacji danych i ewaluacji\n",
    "\n",
    "if not PDE_OK:\n",
    "    raise RuntimeError(\"Moduł PDE wymagany do Zadania 6 (PINN).\")\n",
    "\n",
    "# Ustaw parametry PDE po asymilacji\n",
    "p_assim = Params(**vars(p_base))\n",
    "p_assim.alpha_S = alpha_S_assim\n",
    "p_assim.mu_max  = mu_max_assim\n",
    "p_assim.lam     = lam_assim\n",
    "\n",
    "# Symulacja PDE (semi-implicit) → TB(t) oraz stany końcowe do wizualizacji\n",
    "grid = Grid(Nx=Nx_data, Ny=Ny_data, Lx=Lx, Ly=Ly)\n",
    "(S_end, R_end, I_end, C_end), traj, info = run_simulation(\n",
    "    solver_name=\"semi_implicit\",\n",
    "    grid=grid, p=p_assim,\n",
    "    T=T_end, dt=None, save_every=max(1, len(t_eval)//120), theta=0.5\n",
    ")\n",
    "\n",
    "# Referencja TB(t) z traj\n",
    "t_traj = np.array([row[\"t\"] for row in traj])\n",
    "TB_traj = np.array([row[\"tumor_burden\"] for row in traj])\n",
    "TB_pde = np.interp(t_eval, t_traj, TB_traj)\n",
    "\n",
    "# --- Inicjalizacja pól początkowych (IC) dla strat IC PINN ---\n",
    "# POPRAWKA: Użyj funkcji init_fields z modułu PDE dla spójności\n",
    "S0_mat, R0_mat, I0_mat, C0_mat = init_fields(grid)\n",
    "print(f\"[IC] Użyto init_fields() z modułu PDE. S0: [{S0_mat.min():.4e}, {S0_mat.max():.4e}], C0: [{C0_mat.min():.4e}, {C0_mat.max():.4e}]\")\n",
    "\n",
    "# Losowania punktów treningowych\n",
    "n_phys   = 8000   # zwiększone dla lepszej kolokacji\n",
    "n_ic     = 2000\n",
    "n_bc     = 2000\n",
    "n_tb     = 150    # zmniejszone - TB jest globalne, nie potrzebujemy zbyt wielu punktów\n",
    "\n",
    "xs = np.linspace(0,Lx,Nx_data); ys = np.linspace(0,Ly,Ny_data)\n",
    "\n",
    "def sample_uniform_xy(n):\n",
    "    return np.random.rand(n,1)*Lx, np.random.rand(n,1)*Ly\n",
    "\n",
    "# Kolokacja (t,x,y)\n",
    "t_phys = np.random.rand(n_phys,1) * T_end\n",
    "x_phys, y_phys = sample_uniform_xy(n_phys)\n",
    "\n",
    "# IC: t=0 z etykietą z macierzy IC\n",
    "ix_ic = np.random.randint(0, Nx_data, size=n_ic)\n",
    "iy_ic = np.random.randint(0, Ny_data, size=n_ic)\n",
    "t_ic  = np.zeros((n_ic,1))\n",
    "x_ic  = xs[ix_ic][:,None]\n",
    "y_ic  = ys[iy_ic][:,None]\n",
    "S_ic  = S0_mat[ix_ic, iy_ic][:,None]\n",
    "R_ic  = R0_mat[ix_ic, iy_ic][:,None]\n",
    "I_ic  = I0_mat[ix_ic, iy_ic][:,None]\n",
    "C_ic  = C0_mat[ix_ic, iy_ic][:,None]\n",
    "\n",
    "# BC: próbki na brzegu\n",
    "def sample_boundary(n):\n",
    "    sel = np.random.randint(0,4,size=n)\n",
    "    t = np.random.rand(n,1)*T_end\n",
    "    x = np.random.rand(n,1)*Lx\n",
    "    y = np.random.rand(n,1)*Ly\n",
    "    nx = np.zeros((n,1)); ny = np.zeros((n,1))\n",
    "    for i,s in enumerate(sel):\n",
    "        if s==0:   x[i]=0.0; nx[i]=-1.0; ny[i]=0.0\n",
    "        elif s==1: x[i]=Lx;  nx[i]= 1.0; ny[i]=0.0\n",
    "        elif s==2: y[i]=0.0; nx[i]= 0.0; ny[i]=-1.0\n",
    "        else:      y[i]=Ly;  nx[i]= 0.0; ny[i]= 1.0\n",
    "    return t,x,y,nx,ny\n",
    "\n",
    "t_bc, x_bc, y_bc, nx_bc, ny_bc = sample_boundary(n_bc)\n",
    "\n",
    "# TB: losowe czasy i TB_pde(t) jako „dane\" dla straty TB\n",
    "it_tb = np.random.randint(0, len(t_eval), size=n_tb)\n",
    "t_tb  = t_eval[it_tb][:,None]\n",
    "TB_tb = TB_pde[it_tb][:,None]\n",
    "\n",
    "# Zapis referencji TB\n",
    "pd.DataFrame({\"t\": t_eval, \"TB_pde\": TB_pde}).to_csv(\"out/pinn_tb_reference.csv\", index=False)\n",
    "print(\"[Zapisano] out/pinn_tb_reference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90257783",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Normalizacja wejść (POPRAWKA: tworzymy jako funkcję z ustalonymi parametrami) ===\n",
    "class InputNormalizer:\n",
    "    def __init__(self, T_max, Lx, Ly):\n",
    "        self.T_max = T_max\n",
    "        self.Lx = Lx\n",
    "        self.Ly = Ly\n",
    "\n",
    "    def normalize(self, t, x, y):\n",
    "        \"\"\"Mapuje t∈[0,T] → [0,1], x∈[0,Lx] → [-1,1], y∈[0,Ly] → [-1,1]\"\"\"\n",
    "        tn = t / self.T_max\n",
    "        xn = 2.0 * (x / self.Lx) - 1.0\n",
    "        yn = 2.0 * (y / self.Ly) - 1.0\n",
    "        return tn, xn, yn\n",
    "\n",
    "normalizer = InputNormalizer(T_end, Lx, Ly)\n",
    "\n",
    "# Zgrubne skale wyjść zgodne z rzędem wielkości z Twoich symulacji PDE\n",
    "# POPRAWKA: dostosowane do rzeczywistych zakresów z IC\n",
    "OUT_SCALE = {\n",
    "    \"S\": max(float(S0_mat.max()), 1e-4),\n",
    "    \"R\": max(float(R0_mat.max()), 1e-4),\n",
    "    \"I\": max(float(I0_mat.max()), 1e-3),\n",
    "    \"C\": 1.0  # koncentracja leku\n",
    "}\n",
    "print(f\"[Skale wyjść] S: {OUT_SCALE['S']:.4e}, R: {OUT_SCALE['R']:.4e}, I: {OUT_SCALE['I']:.4e}, C: {OUT_SCALE['C']:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=4, width=128, depth=6):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(in_dim, width))\n",
    "        layers.append(nn.Tanh())\n",
    "        for _ in range(depth-1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(width, out_dim))  # [S,R,I,C]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.softplus = torch.nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, t, x, y):\n",
    "        \"\"\"POPRAWKA: Przyjmuje oddzielne tensory t,x,y i normalizuje je wewnętrznie\"\"\"\n",
    "        # Normalizacja wejść\n",
    "        tn, xn, yn = normalizer.normalize(t, x, y)\n",
    "        inp = torch.cat([tn, xn, yn], dim=1)\n",
    "\n",
    "        raw = self.net(inp)  # shape [N, 4] -> [S_raw, R_raw, I_raw, C_raw]\n",
    "\n",
    "        # Softplus + skalowanie, żeby wymusić nieujemność i poprawne rzędy wielkości\n",
    "        S = self.softplus(raw[:, 0:1]) * OUT_SCALE[\"S\"]\n",
    "        R = self.softplus(raw[:, 1:2]) * OUT_SCALE[\"R\"]\n",
    "        I = self.softplus(raw[:, 2:3]) * OUT_SCALE[\"I\"]\n",
    "        C = self.softplus(raw[:, 3:4]) * OUT_SCALE[\"C\"]\n",
    "\n",
    "        return S, R, I, C\n",
    "\n",
    "pinn = MLP().to(device)\n",
    "print(f\"[Model] Parametry: {sum(p.numel() for p in pinn.parameters())/1e6:.3f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10efe10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Parametry fizyczne → tensory\n",
    "D_S = torch.tensor(float(p_assim.D_S), device=device)\n",
    "D_R = torch.tensor(float(p_assim.D_R), device=device)\n",
    "D_I = torch.tensor(float(p_assim.D_I), device=device)\n",
    "D_C = torch.tensor(float(p_assim.D_C), device=device)\n",
    "\n",
    "rho_S   = torch.tensor(float(p_assim.rho_S), device=device)\n",
    "rho_R   = torch.tensor(float(p_assim.rho_R), device=device)\n",
    "Kcap    = torch.tensor(float(p_assim.K), device=device)\n",
    "alpha_S = torch.tensor(float(p_assim.alpha_S), device=device)\n",
    "alpha_R = torch.tensor(float(p_assim.alpha_R), device=device)\n",
    "sigma   = torch.tensor(float(p_assim.sigma), device=device)\n",
    "delta   = torch.tensor(float(p_assim.delta), device=device)\n",
    "gamma_S = torch.tensor(float(p_assim.gamma_S), device=device)\n",
    "gamma_R = torch.tensor(float(p_assim.gamma_R), device=device)\n",
    "lam     = torch.tensor(float(p_assim.lam), device=device)\n",
    "beta    = torch.tensor(float(p_assim.beta), device=device)\n",
    "mu_max  = torch.tensor(float(p_assim.mu_max), device=device)\n",
    "C50     = torch.tensor(float(p_assim.C50), device=device)\n",
    "m_hill  = int(p_assim.m_hill)\n",
    "\n",
    "def mu_hill(C):\n",
    "    Cpos = torch.clamp(C, min=0.0)\n",
    "    r = (Cpos/(C50+1e-12))**m_hill\n",
    "    return mu_max * (r/(1.0 + r))\n",
    "\n",
    "def laplacian(u, x, y):\n",
    "    grads = torch.autograd.grad(u, (x,y), grad_outputs=torch.ones_like(u), create_graph=True)\n",
    "    ux, uy = grads[0], grads[1]\n",
    "    uxx = torch.autograd.grad(ux, x, grad_outputs=torch.ones_like(ux), create_graph=True)[0]\n",
    "    uyy = torch.autograd.grad(uy, y, grad_outputs=torch.ones_like(uy), create_graph=True)[0]\n",
    "    return uxx + uyy, ux, uy\n",
    "\n",
    "def pde_residuals(t, x, y):\n",
    "    \"\"\"POPRAWKA: Używa nowej sygnatury forward() z oddzielnymi argumentami\"\"\"\n",
    "    t.requires_grad_(True); x.requires_grad_(True); y.requires_grad_(True)\n",
    "    S, R, I, C = pinn(t, x, y)\n",
    "    N = S + R\n",
    "\n",
    "    dSdt = torch.autograd.grad(S, t, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
    "    dRdt = torch.autograd.grad(R, t, grad_outputs=torch.ones_like(R), create_graph=True)[0]\n",
    "    dIdt = torch.autograd.grad(I, t, grad_outputs=torch.ones_like(I), create_graph=True)[0]\n",
    "    dCdt = torch.autograd.grad(C, t, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
    "\n",
    "    lapS, _, _ = laplacian(S, x, y)\n",
    "    lapR, _, _ = laplacian(R, x, y)\n",
    "    lapI, _, _ = laplacian(I, x, y)\n",
    "    lapC, _, _ = laplacian(C, x, y)\n",
    "\n",
    "    mu = mu_hill(C)\n",
    "\n",
    "    # Równania PDE (bez źródła dawkowania - to jest wchłonięte przez dane TB)\n",
    "    fS = dSdt - (D_S*lapS + rho_S*S*(1.0 - N/Kcap) - alpha_S*C*S - gamma_S*I*S - mu*S)\n",
    "    fR = dRdt - (D_R*lapR + rho_R*R*(1.0 - N/Kcap) - alpha_R*C*R - gamma_R*I*R + mu*S)\n",
    "    fI = dIdt - (D_I*lapI + sigma*N - delta*I)\n",
    "    fC = dCdt - (D_C*lapC - lam*C - beta*C*N)\n",
    "\n",
    "    return fS, fR, fI, fC, S, R, I, C\n",
    "\n",
    "# Tensory danych\n",
    "to_t = lambda a: torch.tensor(a, dtype=torch.float32, device=device)\n",
    "t_phys_t = to_t(t_phys); x_phys_t = to_t(x_phys); y_phys_t = to_t(y_phys)\n",
    "\n",
    "t_ic_t = to_t(t_ic); x_ic_t = to_t(x_ic); y_ic_t = to_t(y_ic)\n",
    "S_ic_t = to_t(S_ic); R_ic_t = to_t(R_ic); I_ic_t = to_t(I_ic); C_ic_t = to_t(C_ic)\n",
    "\n",
    "t_bc_t = to_t(t_bc); x_bc_t = to_t(x_bc); y_bc_t = to_t(y_bc)\n",
    "nx_bc_t = to_t(nx_bc); ny_bc_t = to_t(ny_bc)\n",
    "\n",
    "t_tb_t  = to_t(t_tb)              # [n_tb,1]\n",
    "TB_tb_t = to_t(TB_tb)             # [n_tb,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58a91b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === POPRAWKA KRYTYCZNA: TB(t) z gradientami ===\n",
    "def pinn_TB_batch(t_vec_1d: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    POPRAWKA: Usuwa no_grad() i używa prawidłowej kwadratury\n",
    "    t_vec_1d: tensor [M, 1] (na device), zwraca TB dla każdego t (tensor [M,1]).\n",
    "    \"\"\"\n",
    "    M = t_vec_1d.shape[0]\n",
    "    # Siatka kwadratury (zmniejszona dla szybkości, ale zachowująca gradients)\n",
    "    qN = 32\n",
    "    x = torch.linspace(0.0, Lx, qN, device=device)\n",
    "    y = torch.linspace(0.0, Ly, qN, device=device)\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')\n",
    "    Xf = X.reshape(-1, 1); Yf = Y.reshape(-1, 1)\n",
    "    dx = Lx / (qN - 1)\n",
    "    dy = Ly / (qN - 1)\n",
    "    dA = dx * dy  # Element powierzchni\n",
    "\n",
    "    TB_list = []\n",
    "    for i in range(M):\n",
    "        t_col = t_vec_1d[i:i+1].expand(qN * qN, 1)  # [qN^2, 1]\n",
    "        S, R, I, C = pinn(t_col, Xf, Yf)\n",
    "        TB_integral = (S + R).sum() * dA  # Prawidłowa kwadratura prostokątów\n",
    "        TB_list.append(TB_integral)\n",
    "\n",
    "    return torch.stack(TB_list).unsqueeze(1)  # [M,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab91b1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Wagi strat (dostrojone)\n",
    "w_phys = 1.0\n",
    "w_ic   = 10.0   # zwiększone - IC jest kluczowy\n",
    "w_bc   = 1.0\n",
    "w_tb   = 100.0  # mocno zwiększone - TB jest głównym sygnałem danych\n",
    "\n",
    "optimizer = optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=200, verbose=True)\n",
    "\n",
    "def bc_penalty(t, x, y, nx, ny):\n",
    "    \"\"\"Warunki brzegowe Neumanna (zero-flux)\"\"\"\n",
    "    t.requires_grad_(True); x.requires_grad_(True); y.requires_grad_(True)\n",
    "    S, R, I, C = pinn(t, x, y)\n",
    "\n",
    "    _, Sx, Sy = laplacian(S, x, y)\n",
    "    _, Rx, Ry = laplacian(R, x, y)\n",
    "    _, Ix, Iy = laplacian(I, x, y)\n",
    "    _, Cx, Cy = laplacian(C, x, y)\n",
    "\n",
    "    dnS = Sx*nx + Sy*ny\n",
    "    dnR = Rx*nx + Ry*ny\n",
    "    dnI = Ix*nx + Iy*ny\n",
    "    dnC = Cx*nx + Cy*ny\n",
    "\n",
    "    return (dnS**2).mean() + (dnR**2).mean() + (dnI**2).mean() + (dnC**2).mean()\n",
    "\n",
    "def ic_penalty():\n",
    "    \"\"\"Warunki początkowe\"\"\"\n",
    "    S, R, I, C = pinn(t_ic_t, x_ic_t, y_ic_t)\n",
    "    return ((S-S_ic_t)**2).mean() + ((R-R_ic_t)**2).mean() + ((I-I_ic_t)**2).mean() + ((C-C_ic_t)**2).mean()\n",
    "\n",
    "def tb_penalty():\n",
    "    \"\"\"POPRAWKA: Teraz z gradientami!\"\"\"\n",
    "    TB_pred = pinn_TB_batch(t_tb_t)  # [n_tb,1]\n",
    "    return ((TB_pred - TB_tb_t)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening\n",
    "history = []\n",
    "epochs = 3000\n",
    "t0 = time.time()\n",
    "\n",
    "print(\"[Trening] Rozpoczynam...\")\n",
    "print(f\"  Kolokacja PDE: {n_phys} punktów\")\n",
    "print(f\"  IC: {n_ic} punktów\")\n",
    "print(f\"  BC: {n_bc} punktów\")\n",
    "print(f\"  TB: {n_tb} punktów czasowych\")\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    pinn.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Straty składowe\n",
    "    fS, fR, fI, fC, _,_,_,_ = pde_residuals(t_phys_t, x_phys_t, y_phys_t)\n",
    "    L_phys = (fS**2).mean() + (fR**2).mean() + (fI**2).mean() + (fC**2).mean()\n",
    "    L_ic   = ic_penalty()\n",
    "    L_bc   = bc_penalty(t_bc_t, x_bc_t, y_bc_t, nx_bc_t, ny_bc_t)\n",
    "    L_tb   = tb_penalty()\n",
    "\n",
    "    # Łączna strata\n",
    "    loss = w_phys*L_phys + w_ic*L_ic + w_bc*L_bc + w_tb*L_tb\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if ep % 100 == 0 or ep == 1:\n",
    "        elapsed = time.time()-t0\n",
    "        history.append({\n",
    "            \"ep\":ep,\n",
    "            \"L\":float(loss.item()),\n",
    "            \"L_phys\":float(L_phys.item()),\n",
    "            \"L_ic\":float(L_ic.item()),\n",
    "            \"L_bc\":float(L_bc.item()),\n",
    "            \"L_tb\":float(L_tb.item()),\n",
    "            \"time\":elapsed\n",
    "        })\n",
    "        print(f\"[{ep:5d}] L={loss.item():.3e}  phys={L_phys.item():.3e}  ic={L_ic.item():.3e}  bc={L_bc.item():.3e}  tb={L_tb.item():.3e}  time={elapsed:.1f}s\")\n",
    "\n",
    "print(f\"[Trening] Zakończono w {time.time()-t0:.1f}s\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(\"out/pinn_training_history.csv\", index=False)\n",
    "torch.save(pinn.state_dict(), \"out/pinn_model.pt\")\n",
    "print(\"[Zapisano] out/pinn_training_history.csv\")\n",
    "print(\"[Zapisano] out/pinn_model.pt\")\n",
    "\n",
    "# Wykres historii treningu\n",
    "plt.figure(figsize=(10,6))\n",
    "df_hist = pd.DataFrame(history)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(df_hist[\"ep\"], df_hist[\"L\"], label=\"Total Loss\")\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(df_hist[\"ep\"], df_hist[\"L_phys\"], label=\"Physics\")\n",
    "plt.plot(df_hist[\"ep\"], df_hist[\"L_ic\"], label=\"IC\")\n",
    "plt.plot(df_hist[\"ep\"], df_hist[\"L_bc\"], label=\"BC\")\n",
    "plt.plot(df_hist[\"ep\"], df_hist[\"L_tb\"], label=\"TB\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "savefig_fig(\"figs/pinn_training_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja\n",
    "pinn.eval()\n",
    "\n",
    "def pinn_TB_at_time(t_scalar: float) -> float:\n",
    "    \"\"\"Zwraca TB(t) z PINN dla pojedynczego czasu t_scalar\"\"\"\n",
    "    t_one = torch.tensor([[t_scalar]], dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        tb = pinn_TB_batch(t_one)  # [1,1]\n",
    "    return float(tb.item())\n",
    "\n",
    "# PINN → TB(t)\n",
    "print(\"[Ewaluacja] Obliczam TB(t) z PINN...\")\n",
    "TB_pinn = np.array([pinn_TB_at_time(ti) for ti in t_eval])\n",
    "\n",
    "# ODE → TB(t) (te same parametry co PDE po asymilacji)\n",
    "print(\"[Ewaluacja] Obliczam TB(t) z ODE...\")\n",
    "TB0 = TB_pde[0]\n",
    "y0_ode = np.array([0.9*TB0, 0.1*TB0, 0.02, 0.0])\n",
    "p_ode = ODEParams(\n",
    "    alpha_S=float(alpha_S_assim),\n",
    "    mu_max=float(mu_max_assim),\n",
    "    lam=float(lam_assim),\n",
    "    **{k:v for k,v in vars(p_assim).items() if k in ['rho_S','rho_R','K','alpha_R','sigma','delta','gamma_S','gamma_R','beta','C50','m_hill','dose_type','dose_A','dose_period']}\n",
    ")\n",
    "sim_ode = simulate_ode(p_ode, y0_ode, t_eval)\n",
    "TB_ode = sim_ode[\"TB\"]\n",
    "\n",
    "# RMSE + zapis\n",
    "def rmse(a,b):\n",
    "    return float(np.sqrt(np.mean((np.asarray(a)-np.asarray(b))**2)))\n",
    "\n",
    "metrics = {\n",
    "    \"rmse_pinn_vs_pde\": rmse(TB_pinn, TB_pde),\n",
    "    \"rmse_ode_vs_pde\":  rmse(TB_ode,  TB_pde),\n",
    "    \"rmse_pinn_vs_ode\": rmse(TB_pinn, TB_ode),\n",
    "    \"mae_pinn_vs_pde\": float(np.mean(np.abs(TB_pinn - TB_pde))),\n",
    "    \"mae_ode_vs_pde\": float(np.mean(np.abs(TB_ode - TB_pde))),\n",
    "    \"mae_pinn_vs_ode\": float(np.mean(np.abs(TB_pinn - TB_ode)))\n",
    "}\n",
    "save_json(metrics, \"out/pinn_metrics.json\")\n",
    "\n",
    "# CSV z krzywymi\n",
    "pd.DataFrame({\"t\": t_eval, \"TB_pde\": TB_pde, \"TB_pinn\": TB_pinn, \"TB_ode\": TB_ode}).to_csv(\n",
    "    \"out/pinn_tb_curves.csv\", index=False\n",
    ")\n",
    "\n",
    "# Wykres porównawczy TB(t)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(t_eval, TB_pde, 'b-', linewidth=2, label=\"PDE (referencja)\")\n",
    "plt.plot(t_eval, TB_pinn, 'r--', linewidth=2, label=\"PINN\")\n",
    "plt.plot(t_eval, TB_ode, 'g:', linewidth=2, label=\"ODE\")\n",
    "plt.xlabel(\"Czas t\", fontsize=12)\n",
    "plt.ylabel(\"TB(t) = ∫(S+R) dx dy\", fontsize=12)\n",
    "plt.title(\"Porównanie trajektorii TB(t): PINN vs PDE vs ODE\", fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "savefig_fig(\"figs/pinn_tb_compare.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[Metryki]\")\n",
    "print(f\"  RMSE(PINN vs PDE) = {metrics['rmse_pinn_vs_pde']:.6f}\")\n",
    "print(f\"  RMSE(ODE  vs PDE) = {metrics['rmse_ode_vs_pde']:.6f}\")\n",
    "print(f\"  RMSE(PINN vs ODE) = {metrics['rmse_pinn_vs_ode']:.6f}\")\n",
    "print(f\"  MAE(PINN vs PDE)  = {metrics['mae_pinn_vs_pde']:.6f}\")\n",
    "print(f\"  MAE(ODE  vs PDE)  = {metrics['mae_ode_vs_pde']:.6f}\")\n",
    "print(f\"  MAE(PINN vs ODE)  = {metrics['mae_pinn_vs_ode']:.6f}\")\n",
    "print(\"[Zapisano] out/pinn_tb_curves.csv, out/pinn_metrics.json, figs/pinn_tb_compare.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porównanie pól przestrzennych w chwili końcowej\n",
    "print(\"[Ewaluacja] Obliczam pola przestrzenne w t=T_end...\")\n",
    "\n",
    "x_grid = np.linspace(0.0, Lx, Nx_data)\n",
    "y_grid = np.linspace(0.0, Ly, Ny_data)\n",
    "XG, YG = np.meshgrid(x_grid, y_grid, indexing=\"ij\")\n",
    "\n",
    "XG_t = torch.tensor(XG.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "YG_t = torch.tensor(YG.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "tcol = torch.full((XG_t.shape[0], 1), T_end, dtype=torch.float32, device=device)\n",
    "\n",
    "# Ewaluacja PINN\n",
    "pinn.eval()\n",
    "with torch.no_grad():\n",
    "    S_pinn, R_pinn, I_pinn, C_pinn = pinn(tcol, XG_t, YG_t)\n",
    "    Sg = S_pinn.reshape(Nx_data, Ny_data).cpu().numpy()\n",
    "    Rg = R_pinn.reshape(Nx_data, Ny_data).cpu().numpy()\n",
    "    Ig = I_pinn.reshape(Nx_data, Ny_data).cpu().numpy()\n",
    "    Cg = C_pinn.reshape(Nx_data, Ny_data).cpu().numpy()\n",
    "\n",
    "# Funkcja pomocnicza do porównań i zapisu\n",
    "def save_compare_field(Z_pde, Z_pinn, name):\n",
    "    vmax = max(Z_pde.max(), Z_pinn.max())\n",
    "    vmin = min(Z_pde.min(), Z_pinn.min())\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 3.5))\n",
    "\n",
    "    # PDE\n",
    "    im0 = axs[0].imshow(Z_pde.T, origin=\"lower\", extent=(0, Lx, 0, Ly),\n",
    "                        vmin=vmin, vmax=vmax, cmap=\"viridis\")\n",
    "    axs[0].set_title(f\"{name} — PDE (ref.)\", fontsize=11)\n",
    "    axs[0].set_xlabel(\"x\"); axs[0].set_ylabel(\"y\")\n",
    "\n",
    "    # PINN\n",
    "    im1 = axs[1].imshow(Z_pinn.T, origin=\"lower\", extent=(0, Lx, 0, Ly),\n",
    "                        vmin=vmin, vmax=vmax, cmap=\"viridis\")\n",
    "    axs[1].set_title(f\"{name} — PINN\", fontsize=11)\n",
    "    axs[1].set_xlabel(\"x\"); axs[1].set_ylabel(\"y\")\n",
    "\n",
    "    # Różnica\n",
    "    diff = Z_pinn - Z_pde\n",
    "    vmax_diff = max(abs(diff.min()), abs(diff.max()))\n",
    "    im2 = axs[2].imshow(diff.T, origin=\"lower\", extent=(0, Lx, 0, Ly),\n",
    "                        vmin=-vmax_diff, vmax=vmax_diff, cmap=\"RdBu_r\")\n",
    "    axs[2].set_title(f\"{name} — Różnica (PINN - PDE)\", fontsize=11)\n",
    "    axs[2].set_xlabel(\"x\"); axs[2].set_ylabel(\"y\")\n",
    "\n",
    "    # Colorbars\n",
    "    fig.colorbar(im1, ax=axs[:2].ravel().tolist(), shrink=0.8, label=name)\n",
    "    fig.colorbar(im2, ax=axs[2], shrink=0.8, label=\"Różnica\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fname = f\"figs/pinn_vs_pde_field_{name}.png\"\n",
    "    plt.savefig(fname, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"[Zapisano wykres] {fname}\")\n",
    "\n",
    "    # Statystyki błędu\n",
    "    rmse_field = np.sqrt(np.mean((Z_pinn - Z_pde)**2))\n",
    "    mae_field = np.mean(np.abs(Z_pinn - Z_pde))\n",
    "    max_err = np.max(np.abs(Z_pinn - Z_pde))\n",
    "    print(f\"  {name}: RMSE={rmse_field:.4e}, MAE={mae_field:.4e}, MAX_ERR={max_err:.4e}\")\n",
    "\n",
    "# Porównania\n",
    "save_compare_field(S_end, Sg, \"S\")\n",
    "save_compare_field(R_end, Rg, \"R\")\n",
    "save_compare_field(I_end, Ig, \"I\")\n",
    "save_compare_field(C_end, Cg, \"C\")\n",
    "\n",
    "# Zapisz pola PINN\n",
    "np.savez(\"out/pinn_final_fields.npz\", S=Sg, R=Rg, I=Ig, C=Cg)\n",
    "print(\"[Zapisano] out/pinn_final_fields.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c420ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podsumowanie końcowe\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PODSUMOWANIE ZADANIA 6 — PINN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nParametry po asymilacji (źródło: {src}):\")\n",
    "print(f\"  alpha_S = {alpha_S_assim:.4f}\")\n",
    "print(f\"  mu_max  = {mu_max_assim:.4f}\")\n",
    "print(f\"  lam     = {lam_assim:.4f}\")\n",
    "\n",
    "print(f\"\\nArchitektura PINN:\")\n",
    "print(f\"  Szerokość: 128, Głębokość: 6\")\n",
    "print(f\"  Parametry: {sum(p.numel() for p in pinn.parameters())/1e6:.3f}M\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "print(f\"\\nTrening:\")\n",
    "print(f\"  Epoki: {epochs}\")\n",
    "print(f\"  Czas: {history[-1]['time']:.1f}s\")\n",
    "print(f\"  Końcowa strata: {history[-1]['L']:.3e}\")\n",
    "\n",
    "print(f\"\\nMetryki TB(t):\")\n",
    "print(f\"  RMSE(PINN, PDE) = {metrics['rmse_pinn_vs_pde']:.6f}\")\n",
    "print(f\"  RMSE(ODE,  PDE) = {metrics['rmse_ode_vs_pde']:.6f}\")\n",
    "print(f\"  MAE(PINN,  PDE) = {metrics['mae_pinn_vs_pde']:.6f}\")\n",
    "print(f\"  MAE(ODE,   PDE) = {metrics['mae_ode_vs_pde']:.6f}\")\n",
    "\n",
    "print(f\"\\nPliki wyjściowe:\")\n",
    "print(f\"  - out/pinn_model.pt (wagi sieci)\")\n",
    "print(f\"  - out/pinn_training_history.csv (historia treningu)\")\n",
    "print(f\"  - out/pinn_tb_curves.csv (trajektorie TB)\")\n",
    "print(f\"  - out/pinn_metrics.json (metryki)\")\n",
    "print(f\"  - out/pinn_final_fields.npz (pola końcowe)\")\n",
    "print(f\"  - figs/pinn_tb_compare.png (porównanie TB)\")\n",
    "print(f\"  - figs/pinn_vs_pde_field_*.png (porównania pól)\")\n",
    "print(f\"  - figs/pinn_training_loss.png (krzywe uczenia)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Zadanie 6 zakończone pomyślnie!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
